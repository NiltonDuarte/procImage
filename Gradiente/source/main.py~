# -*- coding: utf-8 -*-
from eyeTracking import *
import cv2
import numpy as np




img = cv2.imread('face3.png',0)



eT = eyeTracking((290, 191), (420, 184))



cap = cv2.VideoCapture('face.mov')
ret = True

rightPos = []
leftPos = []



while(cap.isOpened() and ret):
	ret, frame = cap.read()
	#frame = img

	if ret:
		gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
		grayg = cv2.GaussianBlur(gray,(7,7),2);

		print "EyeTrack"
		eT.setImg(grayg)
		eT.eyeTracking()
		
		#print "right eye", eT.rightEyeCoord
		cv2.circle(frame, eT.rightEyeCoord, 3,  255, 2, 8, 0 )
		cv2.circle(frame, eT.leftEyeCoord, 3,  255, 2, 8, 0 )
		#print "eT.rightEyeCoord = ", eT.rightEyeCoord
		rightPos.append(eT.rightEyeCoord)
		leftPos.append(eT.leftEyeCoord)
		print rightPos
		print leftPos

		cv2.imshow('frame',frame)
		if cv2.waitKey(1) & 0xFF == ord('q'):
			break
		#a = raw_input("da enter")




cap.release()
cv2.destroyAllWindows()

